# 자료구조 정리

## Linked List

배열 중 특이한 배열이며 자기 자신 바로 다음에 어떤 원소가 오는지만 기억하고 있다. 그래서 배열의 삽입과 삭제를 하는데 매우 적은 시간이 소모된다.

하지만 `Search`에는 보다 많은 시간이 걸립니다.

하지만 `Linked List`는 이 개념 그자체 보다 `tree`에 근간이 되는 자료구조이기에 더 가치가 크다고 할 수 있습니다.

## Tree

트리는 비선형 구조 이며 계층적  관계를 표현하는 자료 구조입니다. 트리는 어떤 원소를 꺼내고 집어 넣는다는 것 보다는 표현에 집중하는 자료 구조입니다.

구성요소

- 노드 : 트리를 구성하는 각각의 요소
- 간선 : 노드와 노드를 연결하는 선
- 루트 노드 : 최상위에 있는 노드
- 단말 노드 : 하위에 다른 노드가 연결되어 있지 않은 노드
- 내부노드 : 단말노드를 제외한 모든 노드, 루트노드를 포함한다.

### Binary Tree

이진트리는 루트를 중심으로 2개의 서브트리로 나누어진다. 또한 나눠지 서브트리 또한 2개의 서브트리를 가져야한다.

트리의 각층을 `level`로 칭하며  루트 노드의 `level`은 0 이며 가장 높은 `level`을 높이라 칭한다.

**포화이진트리**

모든 레벨이 꽉 찬 트리를 가르쳐 포화 이진 트리라고 한다. 위에서 아래로 왼쪽에서 오른쪽으로 차곡 차곡 채워진 이진 트리이다.  하지만 마지막 층이 꽉 채워져 있지 않아도 중간에 비는 노드가 없으면 포화이진트리이다.

**완전이진트리**

포화 이진 트리에서 마지막 층 까지 꽉채워진 것을 완전이진 트리라고 한다.

**정이진트리**

모든 노드가 0개 또는 2개의 하위노드를 가르쳐 정 이진 트리라고 합니다.

### Binary Search Tree

이진 탐색 트리는 효율적인 탐색을 위한 저장방법을 고민할 결과 만들어진 트리이다. 

규칙

- 이진 탐색 트리의 노드에 저장된 키는 유일하다.
- 부모의 키가 왼쪽 자식의 키보다 크다.
- 부모의 키가 오른쪽 자식 노드의 키보다 작다.
- 왼쪽와 오른쪽 서브트리도 이진 탐색 트리이다.

이진 탐색 트리의 탐색 연산는 O(log n)  의 시간 복잡도를 갖는다 사실 정확하게 얘기하면 O(h)라고 하는 것이 맞다. 하지만 편향 트리가 생성된다면 최악의 시간 복잡도는 O(n)이 된다. 

배열 보다 많은 메모리를 사용하지만 배열과 같은 시간복잡도를 가지게되는 비효율 적인 상황이 발생한다. 이를 하기위해 트리의 구조를 재조정하는 기법이 있는데 그것 중 하나가 `Red-Black Tree`이다.

### Binary Heap

자료 구조의 일종으로 Tree 중에도 배열에 기반한 `Complete Binary Tree`이다. 배열에 트리의 값들을 넣어 줄때, 0번째는 건너뛰고 1번 `index`부터 루트노드가 시작된다. 이는 노드의 고유 번호 값과 배열의 `index`를 일치시켜 혼동을 줄이기 위함이다. `Heap`에는 최대힙, 최소힙 두 종류가 있다.

최대힙이란 각 노드의 값이 해당 `children`의 값보다 크거나 같은 `complete binary tree`를 말한다. (최소힙은 그 반대이다.)

최대힙 에서는 루트 노드에 있는 값이 가장 크므로 최대값을 찾는데 O(1) 이며 최소힙도 마찬가지 이다. 하지만 heap구조를 계속 유지하기 위해서는 제거된 루트 노드를 대체할 다른 노드가 필요하다. 여기서 heap은 맨 마지막을 로트 노드로 대체 시킨 후 다시 heapify과정을 거쳐 heap구조를 유지한다. 이런 경우에는 결곡 O(log n) 의 시간 복잡도로 최대값 도는 최소값에 접근할 수 있게 된다.

### Heapify

`heapify`란 최대 힙 또는 최소힙으로 만드는 과정을 일컫는다.

중간노드에서 시작하여서 루트노드까지 올라가면서 `heapify`를 진행하면 `최대힙`또는 `최소힙`을 만들어 낼 수 있다.

```python
def heapify(arr, mid, size):
    presentNode = mid
    leftChildren = mid * 2
    rightChildren = mid * 2 + 1
    largestNode = presentNode
    
    if (leftChildren < size and arr[leftChildren] > arr[largestNode]):
        largestNode = leftChildren
    if (rightChildren < size and arr[rightChildren] > arr[largestNode]):
        largestNode = rightChildren
    
    if (presentNode != largestNode):
        arr[presentNode], arr[largestNode] = arr[largestNode], arr[presentNode]
        heapify(arr, largestNode, size)
        
def makeMaxHeap(arr):
    for mid in range(len(arr) // 2 - 1, 0, -1):
        heapify(arr, mid, len(arr))
```

 이런식으로 `heapify`를 `mid`노드부터 순차적으로 올라가면서 `root`노드까지 진행 하면 `maxHeap`을 만들 수 있다. 부등호만 조금 만지면 `minHeap`도 당연히 만들 수 있다.

### Heap sort

힙 정렬 또한 `heapify`를 이용한 `heap`트리 만들기를 이용해서 할 수 있다. 오름 차순은 최대힙 그리고 내림차순은 최소 힙을 이용해서 만들면 된다.

오름 차순 정렬을 한다고 했을때, 

1.  최대힙을 만든다.
2. 루트 노드와 마지막 노드의 값을 바꾼다.
3. 사이즈를 1 줄인다.

1 ~ 3 번을 반복하면 오름차순 정렬이 완성된다.

## Hash table

`hash`는 내부적으로 배열을 사용하여 데이터를 저장하기 때문에 빠른 검색 속도를 갖는다. 특정한 값을  찾는데 데이터 고유의 인덱스로 접근하기때문에 O(1)의 시간 복잡도를 갖는다. 하지만 문제는 이 인덱스로 저장되는 `key `값이 불규칙 하다는 것이다.

그래서 특별한 알고리즘을 이용하여 데이터와 연관된 고유한 숫자를 만들어 낸 뒤 이를 인덱스로 사용한다. 특정 데이터가 저장되는 인덱스는 그 데이터 만의 고유한 위치이기 때문에, 삽입 연산시 다른 데이터의 사이에 끼어들가나, 삭제시 다른 데이터로 채울 필요가 없으므로 연산에서 추가적인 비용이 없도록 만들어진 구조이다.

### Hash Function

인덱스를 만드는 특별한 알고리즘을 말한다. 

하지만 어설픈 `hash function`을 통해서 `key`값을 정한다면 동일한 값이 도출 될 수 가 있다. 이렇게 되면 동일한 `key`값에 복수 개의 데이터가 하나의 테이블에 존재할 수 있게 되는 것인데, 이를 `Collision`이라고 한다. 

**어떤 hash function이 좋을까?**

무조건 1:1로 대응되는 것이 좋은것은 아니다. collision을 최소화하고 그 와중에 생기는 collision에 대해서 어떻게 대응 할 것인가 를 생각해야한다. 어차피 1: 1로 대응되는 hash function은 만들기도 힘들 뿐더러 만들어도 array와 다르바 없으며 메모리를 너무 차지하게 된다. 

### Resolve Conflict

기본적으로 collision을 해결하는 방법에 대해 알아보자.

1. Open Adress(개방주소방법)

   해시 충돌이 발생하면 다른 해시 버킷에 해당 자료를 삽입하는 방식이다. 버킷이라 바구니와 같은 개념으로 데이터를 저정하기 위한 공간 이라고 생각하면 된다. 즉 주어진 해쉬 테이블 내에서 해결 한다고 생각하면된다. 즉 처음 계산한 해쉬함수를 0번째 해쉬함수, 충돌이 일어난 다음 주소를 계산하는 것이 1번째 해쉬함수.. 이런식으로 표현이 도니다.

   다음 주소를 결정하는 방법이 다양하지만 대표적으로는 

   - 선형조사

     가장 간단한 방법으로 충돌이 일어난 바로 뒷자리를 보는 것이다. 이렇게 하면 i 번째 해쉬함수는 첫 해쉬함수로 정해진 버킷으로 부터 i 번째 떨어진 버킷을 가르킬 것이다. 하지만 맨 마지막 버킷을 넘어서게 되면 다시 첫 버킷으로 돌아오게 된다.

   - 이차원조사

     이는 선형 조사에서는 1차원 적으로 접근해서 범위를 넓혔다면 이차원 조사는 2차원적으로 접근해서 범위를 넓힌다고 볼 수 있습니다. 이는 선현조사에서 흔히 생기는 군집을 방지하지만 하지만 여러개의 원소가 동일한 초기 해쉬 함수 값을 가지게 되면 똑같은 순서로 조사를 하게 되므로 비효율적이 되며 이를 2차 군집이라 한다.

   - 더블해슁

     더블 해슁음 2개의 함수를 사용하는 것을 말한다. 해쉬함수와 충돌이 생겼을 시 새로운 주소를 가지게할 2번째 해쉬함수로 이루어져 있다. 여기서 고려해야할 점은 두번째 해쉬 함수값이 해쉬 테이블 m과 서로소여서 한다. 그렇지 않으면 전체 해쉬 테이블을 모두 보지 못하고 국한된 부분만 보게 될것이기 때문이다.


## Graph

정점과 간선의 집합이며, 앞서 배운 트리도 그래프중 하나 이지만 사이클이 존재하지 않는 그래프를 말한다.

- Undirected Graph : 간선의 방향성이 없는 그래프입니다. 간선 사이로 양쪽 노드로 움직이기 가능하다는 의미입니다.
- Directed Graph(Digraph) : 간선에 방향성이 있는 그래프입니다.
- Weighted Graph : 간선에 가중치가 추가된 그래프입니다.
- Sub Graph : 전체 그래프 중 일부 그래프를 의미합니다.

### 표현 방법

- 인접행렬

  정방 행렬을 사용해서 표현 가능합니다.

- 인접 리스트

  연결 리스트를 사용하는 방법입니다.

## 그래프 탐색 방법

### DFS

깊이 우선 탐색으로 처음 시작점 부터 시작해서 가장 깊이 들어 간 후에 너비를 탐색하는 방법이다. 

stack을 이용한다.

### BFS

이는 dfs 와 다르게 깊게 보다는 넓게 탐색하는 방법이다. 시작점에서 가까운 순으로 탐색하기 때문에 보통 최단거리를 구하는 문제에 많이 이용되는 알고리즘이다.

### MST

최소 신장 트리라고 하며 모든 정점을 지나면서 가장 최단거리로 이동할 수 있는 트리를 말한다. 하지만 사이클이 존재하지 않는 트리여야만 한다.

### Kruskal Algorithm

모든 정점만 있다고 가정하고 모든 정점 들중 가장 가중치가 낮은 간선 부터 연결 해 나간다. 그러기 위해서는 간선을 가중치를 기준으로 오름 차순으로 정렬 해놓아야 한다. 그리고 사이클이 존재하지 않아야 하므로 `union - find`알고리즘을 이용해서 같은 노드가 한 집합에 2번 존재 하지 않게 함으로써 사이클이 생기는 것을 방지 할 수 있다.

### Prim Algorithm

최소 신장 트리를 생성하는 또 다른 알고리즘이다.

일단 정점 2개와 1개의 가장 가중치가 낮은 간선으로 이루어진 트리로 초기화한다. 이 트리에서 외부 정점들과 연결 할 수 있는 노드들 중 그 간선의 가중치가 가장 낮은 것 들부터 연결한다. 여기서도 물론 사이클이 생기지 않게끔 연결해야 한다.

